<div align="center">

# ğŸ§  Reinforcement Learning

*A comprehensive repository for learning Reinforcement Learning through theory, algorithms, and hands-on practice.*

[![Author](https://img.shields.io/badge/Author-mohd--faizy-blue?style=for-the-badge&logo=github&logoColor=white)](https://github.com/mohd-faizy)
[![Python](https://img.shields.io/badge/Python-3.13%2B-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.8.0-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![Gymnasium](https://img.shields.io/badge/Gymnasium-1.2.0-008000?style=for-the-badge&logo=openai&logoColor=white)](https://gymnasium.farama.org/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebooks-F37626?style=for-the-badge&logo=jupyter&logoColor=white)](https://jupyter.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](LICENSE)

</div>

---

## ğŸ“š Table of Contents

- [ğŸ§  Reinforcement Learning](#-reinforcement-learning)
  - [ğŸ“š Table of Contents](#-table-of-contents)
  - [ğŸ›£ï¸ Learning Roadmap](#ï¸-learning-roadmap)
  - [ğŸ§¬ What is Reinforcement Learning?](#-what-is-reinforcement-learning)
    - [ğŸŒŸ Real-World Applications](#-real-world-applications)
    - [ğŸ› ï¸ Core Components](#ï¸-core-components)
    - [ğŸ§  RL vs Supervised Learning](#-rl-vs-supervised-learning)
  - [ğŸ“ Learning Path](#-learning-path)
    - [ğŸŸ¢ Beginner Level](#-beginner-level)
    - [ğŸŸ¡ Intermediate Level](#-intermediate-level)
    - [ğŸ”´ Advanced Level](#-advanced-level)
  - [âš™ï¸ Installation](#ï¸-installation)
    - [ğŸ“‹ Prerequisites](#-prerequisites)
    - [ğŸš€ Quick Setup](#-quick-setup)
  - [ğŸ“‚ Repository Structure](#-repository-structure)
  - [ğŸš€ Getting Started](#-getting-started)
    - [ğŸ“Š Algorithm Implementations](#-algorithm-implementations)
    - [ğŸ““ Interactive Notebooks](#-interactive-notebooks)
  - [âš–ï¸ License](#ï¸-license)
  - [â¤ï¸ Support](#ï¸-support)
  - [ğŸª™ Credits \& Inspiration](#-credits--inspiration)
    - [ğŸ“š Foundational Resources](#-foundational-resources)
    - [ğŸ› ï¸ Open Source Libraries](#ï¸-open-source-libraries)
    - [ğŸ“ Educational Inspiration](#-educational-inspiration)
  - [ğŸ”— Connect with me](#-connect-with-me)

---

## ğŸ›£ï¸ Learning Roadmap

<div align="center">
  <img src="_img/rl-map.png" alt="Reinforcement Learning Roadmap" width="800"/>
</div>

---

## ğŸ§¬ What is Reinforcement Learning?

Reinforcement Learning (RL) is a branch of machine learning where an **agent** learns to make decisions by interacting with an **environment**. Unlike supervised learning, RL doesn't rely on labeled data. Instead, the agent learns through trial and error, receiving **rewards** or **penalties** for its actions.

### ğŸŒŸ Real-World Applications

- ğŸ¤– **Robotics**: Robot navigation, manipulation, and control
- ğŸ® **Gaming**: AlphaGo, OpenAI Five, StarCraft II agents
- ğŸš— **Autonomous Vehicles**: Path planning and decision making
- ğŸ’° **Finance**: Algorithmic trading and portfolio management
- ğŸ¯ **Recommendation Systems**: Personalized content delivery
- âš¡ **Energy**: Smart grid optimization and resource allocation

---

### ğŸ› ï¸ Core Components

| Component | Description |
|-----------|-------------|
| ğŸ¤– **Agent** | The decision-maker that learns and takes actions |
| ğŸŒ **Environment** | The world the agent interacts with (MDPs, Gym environments) |
| ğŸ **Reward Function** | Feedback signal that guides learning (positive/negative) |
| ğŸ¯ **Policy** | The agent's strategy for choosing actions (deterministic/stochastic) |
| ğŸ’ **Value Function** | Estimates expected future rewards from states/actions |
| ğŸ” **Exploration vs Exploitation** | Balance between trying new actions and using known good ones |
| ğŸ§  **Training Algorithms** | Methods to improve the policy (Q-learning, policy gradients, etc.) |

---

### ğŸ§  RL vs Supervised Learning

| Aspect | Reinforcement Learning | Supervised Learning |
|--------|----------------------|-------------------|
| ğŸ“Š **Feedback Type** | Delayed rewards/penalties | Immediate labels |
| ğŸ“ˆ **Data Requirements** | Sequential interaction data | Static labeled datasets |
| ğŸ¯ **Training Objective** | Maximize cumulative reward | Minimize prediction error |
| ğŸ“¤ **Output** | Policies (action strategies) | Predictions/classifications |
| ğŸ”„ **Learning Style** | Trial and error | Pattern recognition |
| â° **Temporal Aspect** | Sequential decision making | Independent predictions |

---

## ğŸ“ Learning Path

### ğŸŸ¢ Beginner Level
- [x] ğŸ° Multi-Armed Bandits
- [x] ğŸ”„ Markov Decision Processes (MDPs)
- [x] âš¡ Dynamic Programming (Value & Policy Iteration)
- [x] ğŸ² Monte Carlo Methods
- [x] â° Temporal Difference Learning (TD)

### ğŸŸ¡ Intermediate Level
- [x] ğŸ¯ Q-Learning & SARSA
- [ ] ğŸª Expected SARSA & Double Q-Learning
- [ ] ğŸ“ˆ Function Approximation
- [x] ğŸ§  Deep Q-Networks (DQN)
- [ ] ğŸ”§ DQN Variants (Double DQN, Dueling DQN)

### ğŸ”´ Advanced Level
- [ ] ğŸ­ Policy Gradient Methods (REINFORCE)
- [ ] ğŸª Actor-Critic Methods (A2C, A3C)
- [ ] ğŸš€ Proximal Policy Optimization (PPO)
- [ ] ğŸŒŸ Deep Deterministic Policy Gradient (DDPG)
- [ ] ğŸ¯ Soft Actor-Critic (SAC)
- [ ] ğŸ¤ Multi-Agent Reinforcement Learning
- [ ] ğŸ—ï¸ Hierarchical Reinforcement Learning

---

## âš™ï¸ Installation

### ğŸ“‹ Prerequisites

- Python **3.13+**
- [Git](https://git-scm.com/) installed
- [UV](https://docs.astral.sh/uv/getting-started/installation/) package manager (recommended)
- (Optional) CUDA-compatible GPU for deep RL training

### ğŸš€ Quick Setup

```bash
# Clone the repository
git clone https://github.com/mohd-faizy/Reinforcement_learning.git
cd Reinforcement_learning

# Using UV (recommended)
uv venv rl_env
source rl_env/bin/activate   # macOS/Linux
.\rl_env\Scripts\activate    # Windows
uv pip install -r requirements.txt

# Or using pip
pip install -r requirements.txt

# Launch Jupyter Lab to explore notebooks
jupyter lab
```

---

## ğŸ“‚ Repository Structure

```
Reinforcement_learning/
â”œâ”€â”€ ğŸ“ _img/                          # Images and visualizations
â”‚   â”œâ”€â”€ rl-map.png                    # Learning roadmap
â”‚   â”œâ”€â”€ frozen-lake.png               # Environment diagrams
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ğŸ“ 00_RL/                         # Basic RL implementations
â”‚   â”œâ”€â”€ 02_frozen_lake.py             # FrozenLake environment
â”‚   â”œâ”€â”€ 03_mountain_car.py            # MountainCar environment
â”‚   â”œâ”€â”€ 04_taxi-parking.py            # Taxi environment
â”‚   â””â”€â”€ 05_cliffwalking.py            # CliffWalking environment
â”œâ”€â”€ ğŸ“ 01_Q-Learning/                 # Q-Learning implementations
â”‚   â”œâ”€â”€ 00_Q-Learning.ipynb           # Q-Learning tutorial
â”‚   â”œâ”€â”€ 02_cartpole_Q.py              # CartPole with Q-Learning
â”‚   â””â”€â”€ 03_frozen_lake_Q.py           # FrozenLake with Q-Learning
â”œâ”€â”€ ğŸ“ 02_DQN/                        # Deep Q-Network implementations
â”‚   â”œâ”€â”€ 00_cartpole_DQN.py            # CartPole with DQN
â”‚   â””â”€â”€ 01_mountain_car_DQN.py        # MountainCar with DQN
â”œâ”€â”€ ğŸ““ 00_RL_intro.ipynb              # Introduction to RL
â”œâ”€â”€ ğŸ““ 01_Markov_Decision_Processes.ipynb
â”œâ”€â”€ ğŸ““ 02_State_&_Action_value.ipynb
â”œâ”€â”€ ğŸ““ 03_Policy_&_Value_Iteration.ipynb
â”œâ”€â”€ ğŸ““ 05_Monte_Carlo_Methods.ipynb
â”œâ”€â”€ ğŸ““ 06_Temporal_Difference_Learning.ipynb
â”œâ”€â”€ ğŸ““ _Q_vs_DQN.ipynb                # Comparison of Q-Learning vs DQN
â”œâ”€â”€ ğŸ“„ requirements.txt               # Python dependencies
â”œâ”€â”€ ğŸ“„ pyproject.toml                 # Project configuration
â””â”€â”€ ğŸ“„ README.md                      # This file
```

## ğŸš€ Getting Started

### ğŸ“Š Algorithm Implementations

| Algorithm | Implementation | Environment | Status |
|-----------|----------------|-------------|--------|
| ğŸ° **Multi-Armed Bandit** | `00_RL/` | Custom Bandits | âœ… |
| ğŸ¯ **Q-Learning** | `01_Q-Learning/` | FrozenLake, CartPole | âœ… |
| ğŸ§  **Deep Q-Network (DQN)** | `02_DQN/` | CartPole, MountainCar | âœ… |
| ğŸ”„ **Value Iteration** | `03_Policy_&_Value_Iteration.ipynb` | GridWorld | âœ… |
| ğŸ² **Monte Carlo** | `05_Monte_Carlo_Methods.ipynb` | Blackjack | âœ… |
| â° **TD Learning** | `06_Temporal_Difference_Learning.ipynb` | Various | âœ… |

### ğŸ““ Interactive Notebooks

Start your RL journey with these comprehensive notebooks:

1. **[00_RL_intro.ipynb](00_RL_intro.ipynb)** - Fundamentals of RL
2. **[01_Markov_Decision_Processes.ipynb](01_Markov_Decision_Processes.ipynb)** - MDPs and Bellman equations
3. **[02_State_&_Action_value.ipynb](02_State_&_Action_value.ipynb)** - Value functions
4. **[03_Policy_&_Value_Iteration.ipynb](03_Policy_&_Value_Iteration.ipynb)** - Dynamic programming
5. **[05_Monte_Carlo_Methods.ipynb](05_Monte_Carlo_Methods.ipynb)** - MC learning
6. **[06_Temporal_Difference_Learning.ipynb](06_Temporal_Difference_Learning.ipynb)** - TD methods
7. **[_Q_vs_DQN.ipynb](_Q_vs_DQN.ipynb)** - Tabular vs Deep RL comparison

```bash
# Start with the introduction notebook
jupyter lab 00_RL_intro.ipynb
```

---

## âš–ï¸ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


## â¤ï¸ Support

If this repository helped you learn RL, please consider:

- â­ **Starring** this repository
- ğŸ´ **Forking** for your own experiments
- ğŸ“¢ **Sharing** with fellow ML enthusiasts
- ğŸ› **Contributing** improvements and bug fixes

---

## ğŸª™ Credits & Inspiration

This repository builds upon the incredible work of the RL community:

### ğŸ“š Foundational Resources
- ğŸ“– **Sutton & Barto**: *Reinforcement Learning: An Introduction* (The RL Bible)
- ğŸ§  **DeepMind**: Pioneering DQN, AlphaGo, and agent architectures
- ğŸš€ **OpenAI**: Advancing RL research and democratizing AI

### ğŸ› ï¸ Open Source Libraries
- ğŸ® **Gymnasium**: Standard RL environment interface
- ğŸ”¥ **PyTorch**: Deep learning framework
- ğŸ“Š **NumPy & Matplotlib**: Scientific computing and visualization
- ğŸ““ **Jupyter**: Interactive development environment

### ğŸ“ Educational Inspiration
- ğŸ“º **David Silver's RL Course** (DeepMind/UCL)
- ğŸ¥ **Stanford CS234**: Reinforcement Learning
- ğŸ“± **Berkeley CS 285**: Deep Reinforcement Learning

---

## ğŸ”— Connect with me

<div align="center">

[![Twitter](https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/F4izy)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/mohd-faizy/)
[![Stack Exchange](https://img.shields.io/badge/Stack_Exchange-1E5397?style=for-the-badge&logo=stack-exchange&logoColor=white)](https://ai.stackexchange.com/users/36737/faizy)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/mohd-faizy)

</div>

---

<div align="center">

**â­ Star this repository if you found it helpful! â­**

*Happy Learning! ğŸš€*

</div>