{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d48b308",
   "metadata": {},
   "source": [
    "# **✨Markov Decision Processes(MDPs)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638ecb7c",
   "metadata": {},
   "source": [
    "## **📑Table of Contents**\n",
    "\n",
    "1. [Introduction to Markov Decision Processes (MDPs)](#1-introduction-to-markov-decision-processes-mdps)\n",
    "   - 1.1 [Core Concept](#11-core-concept)\n",
    "   - 1.2 [Mathematical Foundation of MDPs](#12-mathematical-foundation-of-mdps)\n",
    "     - 1.2.1 [Why MDPs Matter](#121-why-mdps-matter)\n",
    "     - 1.2.2 [Mathematical Formulation](#122-mathematical-formulation)\n",
    "     - 1.2.3 [Complex Environment Modeling](#123-complex-environment-modeling)\n",
    "\n",
    "2. [Core Components of MDPs](#2-core-components-of-mdps)\n",
    "   - 2.1 [Core Components](#21-core-components)\n",
    "     - 2.1.1 [States (S)](#211-states-s)\n",
    "     - 2.1.2 [Actions (A)](#212-actions-a)\n",
    "     - 2.1.3 [Rewards (R)](#213-rewards-r)\n",
    "     - 2.1.4 [Transition Probabilities (P)](#214-transition-probabilities-p)\n",
    "     - 2.1.5 [Discount Factor (γ)](#215-discount-factor-γ)\n",
    "\n",
    "3. [The Markov Property](#3-the-markov-property)\n",
    "\n",
    "4. [Frozen Lake Environment as MDP](#4-frozen-lake-environment-as-mdp)\n",
    "   - 4.1 [The Solution to the MDP](#41-the-solution-to-the-mdp)\n",
    "   - 4.2 [Frozen Lake Implementation](#42-frozen-lake-implementation)\n",
    "\n",
    "5. [CliffWalking Environment](#5-cliffwalking-environment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf88eecb",
   "metadata": {},
   "source": [
    "## **🔖1. Introduction to Markov Decision Processes (MDPs)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe363b2",
   "metadata": {},
   "source": [
    "### 1.1 **Core Concept**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b978f",
   "metadata": {},
   "source": [
    "> \"**MDP: Models RL environments mathematically**\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f73f81",
   "metadata": {},
   "source": [
    "### 1.2 **Mathematical Foundation of MDPs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c87734e",
   "metadata": {},
   "source": [
    "**Definition:** \n",
    "- A Markov Decision Process (MDP) is a mathematical framework used to model decision-making in environments where outcomes are partly random and partly under the control of a decision-maker (agent). \n",
    "- It's foundational in reinforcement learning and dynamic programming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52138171",
   "metadata": {},
   "source": [
    "#### 1.2.1 Why MDPs Matter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982841e",
   "metadata": {},
   "source": [
    "- **Universal Framework**: MDPs serve as the theoretical foundation for virtually all reinforcement learning algorithms\n",
    "- **Mathematical Rigor**: They provide precise mathematical definitions for `states`, `actions`, and `rewards`\n",
    "- **Optimization Target**: MDPs enable the formulation of optimal policies through well-defined mathematical principles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d6b939",
   "metadata": {},
   "source": [
    "#### 1.2.2 Mathematical Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65237cf1",
   "metadata": {},
   "source": [
    "An MDP is formally defined by a tuple: $(S, A, P, R, \\gamma)$\n",
    "\n",
    "Where:\n",
    "- $S$(`State Space`) $\\rightarrow$ A finite or infinite set of states representing the environment.\n",
    "- $A$(`Action Space`) $\\rightarrow$ A set of actions available to the agent in each state.\n",
    "- $P$(`Transition Probablity`) $\\rightarrow$ A probability function $P(s'|s,a)$ that defines the likelihood of transitioning from state $s$ to $s'$ after taking action $a$.\n",
    "- $R$(`Reward Function`) $\\rightarrow$ A function $R(s,a,s')$ that assigns a reward for moving from state $s$ to $s'$ via action $a$.\n",
    "- $\\gamma$(`Discount Factor`) (0 ≤ γ ≤ 1) $\\rightarrow$ A value in the range [0,1] that determines the importance of future rewards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be434b5",
   "metadata": {},
   "source": [
    "#### 1.2.3 Complex Environment Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3046ac",
   "metadata": {},
   "source": [
    "MDPs excel at modeling complex environments because they:\n",
    "\n",
    "- **Capture Uncertainty**: Through probabilistic state transitions\n",
    "    - Real environments rarely have deterministic outcomes\n",
    "    - Actions may lead to unintended results due to noise, physics, or external factors\n",
    "\n",
    "- **Handle Sequential Decisions**: Through multi-step planning horizons\n",
    "    - Decisions affect not just immediate rewards but future opportunities\n",
    "    - Long-term consequences must be balanced against short-term gains\n",
    "\n",
    "- **Enable Optimization**: Through value-based solution methods\n",
    "    - Mathematical optimization techniques can find provably optimal policies\n",
    "    - Algorithms like dynamic programming guarantee convergence to optimal solutions\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182452be",
   "metadata": {},
   "source": [
    "## **🔖2. Core Components of MDPs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f456b34f",
   "metadata": {},
   "source": [
    "### 2.1 **Core Components:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99472020",
   "metadata": {},
   "source": [
    "#### 2.1.1 **States (S)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b3d492",
   "metadata": {},
   "source": [
    "- **Definition**: States represent all the information necessary to make optimal decisions at any point in time.\n",
    "  \n",
    "- ***Technical Details:***\n",
    "    - **State Space**: The complete set $S = \\{s_1, s_2, ..., s_n\\}$ of all possible states\n",
    "    - **Current State**: Denoted as $s_t$ at time step $t$\n",
    "    - **State Representation**: Must capture all relevant environmental information\n",
    "  \n",
    "- ***State Design Principles:***\n",
    "    - **Completeness**: States must include all information relevant to decision-making\n",
    "    - Missing information leads to suboptimal policies\n",
    "    - Over-inclusion increases computational complexity unnecessarily\n",
    "\n",
    "- **Markov Property Compliance**: \n",
    "    - Current state must fully determine future possibilities\n",
    "    - Past history should be irrelevant given current state\n",
    "    - This enables efficient dynamic programming solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18714d58",
   "metadata": {},
   "source": [
    "#### 2.1.2 **Actions (A)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec0b47",
   "metadata": {},
   "source": [
    "- **Definition**: Actions represent the set of choices available to the agent in each state.\n",
    "  \n",
    "- ***Technical Details:***\n",
    "    - **Action Space**: $A(s)$ represents actions available in state $s$\n",
    "    - **Action Selection**: Denoted as $a_t$ at time step $t$\n",
    "    - **Action Constraints**: Some actions may be state-dependent\n",
    "  \n",
    "- ***Action Space Types:***\n",
    "    - **Discrete Actions**: Finite set of distinct choices\n",
    "        - Examples: {Move Left, Move Right, Move Up, Move Down}\n",
    "        - Easier to analyze mathematically\n",
    "        - Common in grid worlds and board games\n",
    "    \n",
    "    - **Continuous Actions**: Infinite set within bounded ranges\n",
    "        - Examples: Steering angle, throttle position, joint torques\n",
    "        - Requires specialized algorithms (policy gradients, actor-critic)\n",
    "        - Common in robotics and control systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b26575",
   "metadata": {},
   "source": [
    "#### 2.1.3 **Rewards (R)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c7d55",
   "metadata": {},
   "source": [
    "- **Definition**: Rewards provide the optimization signal that guides the agent toward desired behaviors.\n",
    "\n",
    "- ***Mathematical Formulation:***\n",
    "    - **Reward Function**:  $R(s, a)$\n",
    "    - **Immediate Reward**: $r_t$ received at time step $t$\n",
    "    - **Cumulative Return**: $G_t = \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+1}$\n",
    "      - Where:\n",
    "          - $r_t$ = Immediate reward at time $t$\n",
    "          - $\\gamma$ = Discount factor\n",
    "          - $G_t$ = Total discounted return from time $t$\n",
    "\n",
    "- ***Reward Design Strategies:***\n",
    "    - **Sparse Rewards**: Rewards only at goal achievement\n",
    "        - Pro: Clearly defined objectives\n",
    "        - Con: Difficult learning due to credit assignment problem\n",
    "    - **Dense Rewards**: Frequent intermediate rewards\n",
    "        - Pro: Faster learning through immediate feedback\n",
    "        - Con: Risk of reward hacking and unintended behaviors\n",
    "    - **Shaped Rewards**: Carefully designed intermediate rewards\n",
    "        - Guides agent toward goal while maintaining true objective\n",
    "        - Requires domain expertise to design effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3977c",
   "metadata": {},
   "source": [
    "#### 2.1.4 **Transition Probabilities (P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1503614a",
   "metadata": {},
   "source": [
    "- **Definition**: Transition probabilities define the stochastic dynamics of the environment.\n",
    "  \n",
    "- #### Mathematical Formulation:\n",
    "  - $P(s_{t+1} = s' | s_t = s, a_t = a) = P_{ss'}^a$\n",
    "    - Where:\n",
    "        - $P_{ss'}^a$ = Probability of transitioning from state $s$ to state $s'$ under action $a$\n",
    "        - $\\sum_{s'} P_{ss'}^a = 1$ for all $s, a$ (probability distribution property)\n",
    "  \n",
    "- #### Deterministic vs Stochastic Environments:\n",
    "  - **Deterministic**: $P_{ss'}^a \\in \\{0, 1\\}$\n",
    "    - Outcomes are completely predictable\n",
    "    - Simpler to analyze and solve\n",
    "    - Examples: Chess (ignoring time constraints), perfect mazes\n",
    "  \n",
    "  - **Stochastic**: $0 < P_{ss'}^a < 1$ for multiple $s'$\n",
    "    - Outcomes involve uncertainty\n",
    "    - More realistic for real-world problems\n",
    "    - Requires handling of multiple possible outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48577e1a",
   "metadata": {},
   "source": [
    "#### 2.1.5 **Discount Factor (γ)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57be9b6",
   "metadata": {},
   "source": [
    "- **Definition**: The discount factor γ determines the relative importance of immediate versus future rewards in decision-making.\n",
    "\n",
    "- ***Technical Details:***\n",
    "  - **Mathematical Range**: γ ∈  where γ = 0 means only immediate rewards matter, γ = 1 values all future rewards equally[1]\n",
    "  - **Temporal Weighting**: Controls exponential decay of future reward importance\n",
    "  - **Present Value**: Converts future rewards into present value equivalents\n",
    "\n",
    "- ***Mathematical Formulation:***\n",
    "  - **Discounted Return**: $G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + ... = \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1}$\n",
    "  - **Bellman Equation**: $V^{\\pi}(s) = \\mathbb{E}[R_{t+1} + \\gamma V^{\\pi}(S_{t+1}) | S_t = s]$\n",
    "  - **Convergence Guarantee**: When γ < 1, infinite sums converge to finite values\n",
    "\n",
    "- ***Discount Factor Effects:***\n",
    "  - **γ = 0 (Myopic Agent)**: Only immediate rewards considered\n",
    "    - Pro: Fast decision-making, no complex planning required\n",
    "    - Con: Ignores long-term consequences, suboptimal in sequential tasks\n",
    "    - Example: Choosing immediate small reward over delayed large reward\n",
    "  \n",
    "  - **γ = 1 (Farsighted Agent)**: All future rewards weighted equally\n",
    "    - Pro: Optimal long-term planning, considers all consequences\n",
    "    - Con: May struggle in infinite horizon problems, computational challenges\n",
    "    - Example: Sacrificing immediate rewards for much larger future gains\n",
    "  \n",
    "  - **0 < γ < 1 (Balanced Agent)**: Exponentially decreasing future importance\n",
    "    - Balances immediate and future rewards optimally\n",
    "    - Most common in practical applications\n",
    "    - Ensures mathematical convergence and tractable solutions\n",
    "\n",
    "- ***Practical Applications:***\n",
    "  - **Financial Planning**: γ = 0.95-0.99 (high value on future wealth)\n",
    "  - **Robotics Control**: γ = 0.9-0.95 (balance responsiveness with planning)\n",
    "  - **Game Playing**: γ = 0.99 (long-term strategic thinking)\n",
    "  - **Real-time Systems**: γ = 0.5-0.8 (prioritize immediate responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b4697",
   "metadata": {},
   "source": [
    "## **🔖3. The Markov Property**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6425ddb9",
   "metadata": {},
   "source": [
    "> \"**Markov property: Future state depends only on current state and action**\"\n",
    "\n",
    "**Definition:** The Markov Property states that the future state depends only on the `current state` and `action`, **NOT** on the entire history of past states and actions.\n",
    "\n",
    "- **Mathematical Expression:**\n",
    "$$P(S_{t+1} = s' | S_t = s, A_t = a, S_{t-1}, A_{t-1}, ..., S_0, A_0) = P(S_{t+1} = s' | S_t = s, A_t = a)$$\n",
    "\n",
    "- **Intuitive Explanation:** The current state contains all the information needed to make optimal decisions about the future.\n",
    "\n",
    "- **Goal of an Agent in MDP**\n",
    "  - The agent’s objective is to find a policy `𝜋(𝑎∣𝑠)` that maximizes the expected cumulative reward over time. This is often formalized using:\n",
    "      - **Value functions**: Estimate how good it is to be in a state or take an action.\n",
    "      - **Policy iteration** and **value iteration**: Algorithms to compute optimal policies.\n",
    "\n",
    "- **Why the Markov Property Matters**\n",
    "    - **Computational Efficiency**: \n",
    "        - Eliminates need to track and process entire history\n",
    "        - Reduces memory requirements from exponential to linear\n",
    "        - Enables efficient dynamic programming algorithms\n",
    "\n",
    "    - **Mathematical Tractability**:\n",
    "        - Allows use of well-established optimization techniques\n",
    "        - Guarantees convergence properties for many algorithms\n",
    "        - Simplifies analysis of algorithm behavior\n",
    "\n",
    "    - **Policy Optimality**:\n",
    "        - Optimal policies can be expressed as functions of current state only: $\\pi^*(a|s)$\n",
    "        - No need to condition on history: $\\pi^*(a|s, h_t)$ where $h_t$ is history\n",
    "\n",
    "- **Violations and Solutions**\n",
    "    - **Common Violations**:\n",
    "        - **Partial Observability**: Agent cannot observe full state\n",
    "        - **Non-Markovian Dynamics**: Environment has memory or hidden variables\n",
    "        - **Insufficient State Representation**: Missing crucial information\n",
    "\n",
    "    - **Solutions**:\n",
    "        - **State Augmentation**: Include relevant history in state representation\n",
    "        - **Recurrent Policies**: Use RNNs or LSTMs to maintain internal memory\n",
    "        - **Belief States**: Maintain probability distributions over possible states\n",
    "\n",
    "- **Practical Example: Navigation Robot**\n",
    "    - **Markovian Representation**:\n",
    "        - State includes: position, orientation, velocity, sensor readings\n",
    "        - Future position depends only on current state and chosen action\n",
    "        - Past trajectory irrelevant given complete current state\n",
    "\n",
    "    - **Non-Markovian Representation**:\n",
    "        - State includes only: position\n",
    "        - Missing information: orientation, velocity, momentum\n",
    "        - Past movements become relevant for predicting future positions\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123573a7",
   "metadata": {},
   "source": [
    "## **🔖4. Frozen Lake Environment as MDP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ed30f0",
   "metadata": {},
   "source": [
    "- Imagine a 4x4 grid that represents a frozen lake. There are three types of tiles:\n",
    "    - **`S`** : The starting point (safe).\n",
    "    - **`F`** : Frozen surface (safe, you can walk on it).\n",
    "    - **`H`** : A hole in the ice (dangerous, you fall in and the episode ends).\n",
    "    - **`G`** : The goal (where you receive a reward).\n",
    "\n",
    "- A simple layout might look like this:\n",
    "    ```\n",
    "    S  F  F  F\n",
    "    F  H  F  H\n",
    "    F  F  F  H\n",
    "    H  F  F  G\n",
    "    ```\n",
    "\n",
    "> You are an agent (a person trying to cross the lake). Your goal is to find a path from `S` to `G` without falling into a hole `H`.\n",
    "\n",
    "\n",
    "- **Mapping the Problem to a Markov Decision Process (MDP)**\n",
    "    - An MDP is defined by a 5-tuple `(S, A, P, R, γ)`:\n",
    "        - **S**: Set of states\n",
    "        - **A**: Set of actions\n",
    "        - **P**: Transition probabilities `P(s' | s, a)`\n",
    "        - **R**: Reward function `R(s, a, s')`\n",
    "        - **γ**: Discount factor (between 0 and 1)\n",
    "\n",
    "    - Let's break down the Frozen Lake problem into these components.\n",
    "        - 🟢`States (S)`\n",
    "            - Each tile (cell) in the grid is a state. We can represent them by their coordinates.\n",
    "               - **S**: `{(0,0), (0,1), (0,2), (0,3), (1,0), ..., (3,3)}`\n",
    "               - The **terminal states** are the holes `H` and the goal `G`. Once you enter one, the episode is over. For example, `(1,1)` is a hole and `(3,3)` is the goal.\n",
    "\n",
    "        - 🟢`Actions (A)`\n",
    "            - The actions are the possible moves the agent can take from any state (if the move is possible).\n",
    "            -   **A**: `{UP, DOWN, LEFT, RIGHT}`\n",
    "\n",
    "        - 🟢`Transition Probabilities (P)`\n",
    "            - This is the core of the \"Markov\" property. The outcome of an action is **stochastic** (non-deterministic). This mimics the slippery nature of ice.\n",
    "                - **Intended Action**: 33.3% chance\n",
    "                - **Slipping Left**: 33.3% chance\n",
    "                - **Slipping Right**: 33.3% chance\n",
    "\n",
    "            - **Example:** From state `(0,1)` (a frozen tile), if the agent intends to go `DOWN`:\n",
    "                - With ~33% probability, it successfully moves `DOWN` to `(1,1)`.\n",
    "                - With ~33% probability, it slips and moves `LEFT` to `(0,0)`.\n",
    "                - With ~33% probability, it slips and moves `RIGHT` to `(0,2)`.\n",
    "\n",
    "            - If a move would take the agent into a wall (e.g., moving `LEFT` from `(0,0)`), the agent simply stays in its current state. The probability mass for that invalid move is added to the probability of remaining in the current state.\n",
    "\n",
    "        - 🟢`Reward Function (R)`\n",
    "            - The reward defines the goal of the agent. We give a reward only when the agent reaches a meaningful state.\n",
    "                - **Reaching the Goal (G):** `R = +1`\n",
    "                - **Falling into a Hole (H):** `R = 0` (Some versions use a small negative reward like `-1` to penalize failure)\n",
    "                - **Stepping on any other Frozen (F) tile:** `R = 0`\n",
    "\n",
    "            - The agent gets this reward *upon entering* the new state `s'`.\n",
    "                - **Example:**\n",
    "                    - `R((2,3), DOWN, (3,3)) = +1` (Moving into the goal from above)\n",
    "                    - `R((1,0), RIGHT, (1,1)) = 0` (Moving into a hole)\n",
    "                    - `R((0,0), RIGHT, (0,1)) = 0` (Moving onto a frozen tile)\n",
    "\n",
    "        - 🟢`Discount Factor (γ)`\n",
    "            - This determines how much the agent cares about `future rewards` vs. `immediate rewards`.\n",
    "            - Let's choose **γ = 0.9** for this example. This means the agent strongly prefers reaching the goal quickly but still values eventually reaching it over never reaching it at all.\n",
    "\n",
    "\n",
    "\n",
    "- **How an Episode Unrolls**\n",
    "  - Let's simulate a few steps of a possible episode:\n",
    "    - 1.  **Time t=0**: State `s₀ = (0,0)` (Start).\n",
    "    - 2.  **Action a₀**: The agent chooses `RIGHT` (intending to go to `(0,1)`).\n",
    "    - 3.  **Transition**: Due to slippiness, it actually slips and moves `DOWN` to `s₁ = (1,0)`. Reward `r₀ = 0`.\n",
    "    - 4.  **Time t=1**: State `s₁ = (1,0)`.\n",
    "    - 5.  **Action a₁**: The agent chooses `RIGHT` again (intending to go to `(1,1)` - a hole!).\n",
    "    - 6.  **Transition**: It successfully executes the action and moves into the hole at `s₂ = (1,1)`. This is a terminal state.\n",
    "    - 7.  **Reward r₁**: The agent receives `r₁ = 0` for entering a hole. The episode ends. The total return for this episode is `0`.\n",
    "\n",
    "> **A successful episode** would involve the agent navigating the slippery ice, potentially getting lucky with slips, and eventually landing on `(3,3)` to collect a reward of `+1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a4bde6",
   "metadata": {},
   "source": [
    "### The Solution to the MDP\n",
    "\n",
    "- The goal of solving an MDP is to find a **policy (π)**, which is a strategy that tells the agent what action to take in every state (`π(s) -> a`).\n",
    "- The optimal policy `π*` is the one that maximizes the expected cumulative discounted reward (the **return**). \n",
    "- In this case, it's the policy that has the highest chance of getting the agent to the goal without falling in a hole.\n",
    "- For a small grid like this, we can compute this optimal policy using algorithms like **Value Iteration** or **Policy Iteration**. \n",
    "- The result would be a map showing the best action for every tile:\n",
    "\n",
    "![frozen-lake-png](_img\\frozen-lake.png)\n",
    "\n",
    "### **Frozen Lake**\n",
    "- **Environment Description:** An agent must navigate across a frozen lake to reach a goal while avoiding holes.\n",
    "- **Components:**\n",
    "  - **States:** 16 positions (4×4 grid) numbered 0-15\n",
    "  - **Actions:** 4 possible moves (0: left, 1: down, 2: right, 3: up)\n",
    "  - **Terminal States:** Goal state (rewards +1) and hole states (episode ends) ~ 6\n",
    "  - **Transition Probabilities:** Actions don't always lead to expected outcomes due to slippery ice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0234d3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(4)\n",
      "Discrete(16)\n",
      "Number of actions: 4\n",
      "Number of states: 16\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Create environment\n",
    "env = gym.make('FrozenLake-v1', is_slippery=True)\n",
    "\n",
    "# Check state and action spaces\n",
    "print(env.action_space)          \n",
    "print(env.observation_space)    \n",
    "\n",
    "print(\"Number of actions:\", env.action_space.n)      \n",
    "print(\"Number of states:\", env.observation_space.n)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff35a22",
   "metadata": {},
   "source": [
    "## **🔖5. CliffWalking Environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192c299",
   "metadata": {},
   "source": [
    "- The Cliff Walking environment involves an agent crossing a grid world from start to goal while avoiding falling off a cliff.\n",
    "- If the player moves to a cliff location it returns to the start location.\n",
    "- The player makes moves until they reach the goal, which ends the episode.\n",
    "- Your task is to explore the state and action spaces of this environment.\n",
    "\n",
    "![cliff-walking-gif](_img\\cliff_walking.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d23f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 4\n",
      "Number of states: 48\n",
      "[(1.0, np.int64(23), -1, False)]\n",
      "Action: 0 | Probability: 1.0, Next State: 23, Reward: -1, Done: False\n",
      "[(1.0, np.int64(35), -1, False)]\n",
      "Action: 1 | Probability: 1.0, Next State: 35, Reward: -1, Done: False\n",
      "[(1.0, np.int64(47), -1, True)]\n",
      "Action: 2 | Probability: 1.0, Next State: 47, Reward: -1, Done: True\n",
      "[(1.0, np.int64(34), -1, False)]\n",
      "Action: 3 | Probability: 1.0, Next State: 34, Reward: -1, Done: False\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym   \n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Environment Setup\n",
    "# ==============================\n",
    "# Create the CliffWalking environment.\n",
    "# \"CliffWalking-v1\" is a classic control problem from reinforcement learning.\n",
    "# \"render_mode='rgb_array'\" means the environment won't open a window;\n",
    "# instead, it keeps the visual output as an image array (useful for debugging or rendering later).\n",
    "env = gym.make('CliffWalking-v1', render_mode='rgb_array')\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Action and State Spaces\n",
    "# ==============================\n",
    "# Number of possible actions the agent can take (Up, Right, Down, Left = 4).\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "# Number of possible states in the gridworld (4 rows × 12 columns = 48).\n",
    "num_states = env.observation_space.n\n",
    "\n",
    "print(\"Number of actions:\", num_actions)\n",
    "print(\"Number of states:\", num_states)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Exploring Transitions\n",
    "# ==============================\n",
    "# Each state has a set of transitions, depending on the chosen action.\n",
    "# Let's pick a specific state (for example, 35) and explore what happens when we try different actions.\n",
    "state = 35\n",
    "\n",
    "# Loop through all possible actions from this state\n",
    "for action in range(num_actions):\n",
    "    # The environment has an internal dictionary \"P\" that stores transitions.\n",
    "    # P[state][action] gives a list of possible outcomes when taking `action` in `state`.\n",
    "    transitions = env.unwrapped.P[state][action]\n",
    "    print(transitions)\n",
    "\n",
    "    # Each transition has the format: (probability, next_state, reward, done)\n",
    "    # -> probability: chance of this outcome (usually 1.0 for deterministic envs like CliffWalking)\n",
    "    # -> next_state: the state you land in after the action\n",
    "    # -> reward: the reward received for this action\n",
    "    # -> done: whether the episode ends after this transition\n",
    "    for transition in transitions:\n",
    "        probability, next_state, reward, done = transition\n",
    "        print(f\"Action: {action} | Probability: {probability}, Next State: {next_state}, Reward: {reward}, Done: {done}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ecf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 1 — Initial state: [ 0.0273956  -0.00611216  0.03585979  0.0197368 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFeCAYAAAAYIxzjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAACttJREFUeJzt3V+rHHcdx/Hf7J4/SU5iY9t4UaoRjSIEelOsqCBUvDe58BFU22eiz0DoVe+8qze5EAUvqoKhiIiNlkARLEGqrU1r86cnuzMjuwnHHmJPZk/3zKTzeb1CQkjmcL43G975/mZ3qrZt2wIAxJoMPQAAMCwxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOE2hh4AGFbbNOWNX/20tG174HVf/t6PynTzWG9zAf0RAxCvLe+9eWVRBQdeVc92y2Rju1RV1dtkQD8cEwCdNLPdoUcAjogYADqp53eGHgE4ImIA6MRmAMZLDACdNHMxAGMlBoBOGscEMFpiAOikmYkBGCsxAHTimADGSwwAnTgmgPESA0Aniw8dAsZJDEC6qiqfO//sAy/752u/7mUcoH9iACgb2yceeE3bzHuZBeifGIB4VZlsbA09BDAgMQCIAQgnBgAxAOHEACAGIJwYAMpkc3voEYABiQHAZgDCiQGgTMUARBMDgM0AhBMDgBiAcGIAwlVV1em6tm09rAhGSgwAnTX1bOgRgCMgBoCO2tLMbAZgjMQA0E1bHBPASIkBoKO2NLUYgDESA0BnNgMwTmIA6KyZu4EQxkgMAJ3fWtjaDMAoiQGgM/cMwDiJAaBUk0mZbp84+KK2Kbs3rvc1EtAjMQCU6daJcvoLTx14TdvU5frf/tjbTEB/xACw+EziMpluDj0FMBAxAJRq8WO6MfQYwEDEAHB3M7BhMwCpxACwjIHKMQHEEgPA8pjAPQOQSwwAjgkgnBgA7h0TbA09BTAQMQAsjwmmNgMQSwwA9zYD3loIqcQAUKpFDEymHa5sS9s0PUwE9EkMAJ21bVPaZj70GMCaiQGgu7YtTT0begpgzcQA0NniiKCZ2wzA2IgBoLvlMYHNAIyNGAA6a5fHBDYDMDZiAFhtMyAGYHTEALDSZkAMwPiIAaC7tvFuAhghMQCs9DkD7hmA8REDwNLmiUfK9mfOHHjNfPdWuf3utd5mAvohBoClzeOnytbJxw68ppl9WHbff7u3mYB+iAFgqaqmZTLt8nwCYGzEAHDXZFKqiScXQiIxACxV1SIGbAYgkRgAlhYhUE1tBiCRGACWbAYglxgAlmwGIJcYAO6aTMrEZgAiiQHgI8cENgOQSAwA/zsmsBmASGIAWKqqavmzy/MJ2qbpZSagH2IAWEnbzEvb1EOPAayRGABW0jS1GICREQPAShYhIAZgXMQAsHoMtGIAxkQMACuxGYDxEQPAStp6EQPeTQBjIgaAldgMwPiIAWAlYgDGRwwAKxEDMD5iANhz8omvlq1Tjx14za13/l5uv3utt5mAoycGgD0bm8fL5AEPK1psBZraZgDGRAwAe6rpdPkoYyCLVz2wZ/EI48WjjIEsXvXAnmoqBiCRVz2wZ3m/gGMCiONVD+yxGYBMXvXA/hiYTIceA+iZGAD2HRNUVTX0GEDPxACwbzNQHBNAHK96YM/iiKDrPQNt2x75PEA/xACwZ3lE0OGUoK1ni1/7GAnogRgAVtbU88VqYOgxgDURA8ChYqBtm6HHANZEDAArWx4T2AzAaIgBYGVNPXMDIYyIGAAOuRlwTABjIQaAQ94zYDMAYyEGgJW5ZwDGZWPoAYD1appm+fOwuvyPv57Pynw+K2U+/0SfaTCdeg4CPAyq1q4PRuWll14qzz///KG//sc/fLZ856mzZTL5+E8f+v1frpWf/Ox35Z33bx/6+zz99NPl8uXLh/56YH1sBmBkFn0//wT/Y//lq2+Ur3/tibJzbOtjr/nm+SfLqeOb5a1/f3Do71PX9aG/FlgvMQDssztb3Bx49/e3653y9uzJslufLNNqVk5v/qs8uvnW0CMCayYGgH12Z/Vyu3CrPlX+9MF3y836dJm3W2VS6nJscqN88fiVcvb4X4ceE1gjMQDss3tnXmbNVnn1ve+XO+2JvT9vyka51ZwuV29+o2xUd0rbdniiEfCp4K2FwH2bgd9c/8G+EPioumyWP994tnxQP9r7bMDREAPAfZuB5oHvMbIVgDERA8A+Hy7vGRh6CqBPYgC4/90ERQ1AEjEA3HfPwLce+XmZltn//fuq1OX8zm/Lqen13mcDjoYYAPa5c2detqub5duffbnsTK/fi4J2GQHbkxvlKyf+UD5/7PVSVZ5aCGPhrYXAPvOmLb949Y1y8vib5Vb9enlr90vldnNq+XbCRzf/Uf6zda28Vkp5/+bu0KMCfT+b4IUXXljX9wSO0NWrV8srr7xSHnZnzpwpFy9eHHoMGL0XX3xxfZuB55577pPOA/Tg0qVLn4oYePzxx/27Ag+JzjHwzDPPHO0kwFpcuXKlfBrs7Oz4dwUeEm4gBIBwYgAAwokBAAgnBgAgnBgAgHBiAADCiQEACCcGACCcGACAcGIAAMJ5aiGMzNmzZ8uFCxfKw+7cuXNDjwCs+tRCAGCcHBMAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACEEwMAEE4MAEA4MQAA4cQAAIQTAwAQTgwAQDgxAADhxAAAhBMDABBODABAODEAAOHEAACUbP8FEtXkrI+bvrYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFeCAYAAAAYIxzjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAADOJJREFUeJzt3UuPXGdawPHnVFV3dbvdvmDHk0yCEhKGmSEiIEWTkSIhsSCRWARlxwfIIl+BL5JFvkE2SEhsYEGABUlGI5hhMAKSUQYmMPEttvtSfamqU4WqInmwOt2n0l1VJ32e388qty2/7n7kRevvU+c9bzEej8cBAKTVqnsAAKBeYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAguU7dAwD1KQcHMdjfieH+zq8/Hmw/+vXGE8/Gky+9VveYwIKJAUjq9s334/Of/nWMR6OI8Wj6cTweRYzK6cfp78thlN/7w2ivrtU9LrBAYgCSKvv7Meg9PHnN4GC6TgxAs7lnADjWJASG/b26xwAWTAwAxzrcvhcHD2/VPQawYGIAktq48Xx0Lz1x4prhwU4M9raWNhNQDzEASXU3r0VnfbPuMYBvADEASXXWLkZ7pfrGwOnOgvF4KTMB9RADkNQkBFrtlcp15eHedIsh0FxiAJIqWq2IoqhcN9jfjVE5WMpMQD3EAFB5E6EYgGYTA5BYq1393LEHv/hJ9He+WMo8QD3EACR2/buvTm8kPNHkEcVuIIRGEwOQ2Mr65Sha7brHAGomBiCxlY3ZYmBUDm0vhAYTA5DY5C2Coqj+NjDY3/JWATSYGIDEZgmBif7u/S+PNwYaSQwAlXp3//vLGwmBRhIDkNyFG89Vrnnw6T951gA0mBiA5K4++/uTNwzqHgOokRiA5FYvXtMCkJwYgORWL12bad1oOLC9EBpKDEByq+uXZnqb4NAjiaGxxAAwE+cTQHOJAWAmt2/+bd0jAAsiBoCZHj508PDWUmYBlk8MQHZFK57+wZ/WPQVQIzEAfLm9EEhLDADR3ayOgcm2wtHgcCnzAMslBoDodDeqF43H0e89WMY4wJKJAUiuKIrJT9ULx6Pp6YVA84gBYCaTI4z37v+q7jGABRADQLTaK9G9fOPENeNROT29EGgeMQBEe3U9Lj/zYt1jADURA0AUrXasXLg801qHFUHziAFg5hiYvFUwGtpeCE0jBoAoWq1or65VrhuVgxjs7yxlJmB5xAAws3E5iKEYgMYRA8DMBnvbsfP5x3WPAcyZGACm1i7diAtPPHvimsn9Av0dDx6CphEDwFR7bSNWL1ypewygBmIAmGqvdKPdvVC5bjz5YXshNIoYAKZane5MBxaNhv3pC2gOMQBMtdqd6atK2d+PcnCwlJmA5RADwNdSHu5NgwBoDjEAfC2TrYW925/WPQYwR2IAeGTySOLWSrdynRsIoVnEAPDI5re/G93N63WPASyZGAAe6axdjFZndYaVthdCk4gB4JHO2sZMMTA86E1PMASaQQwAjxStzvQEwyqD/e0Yl8OlzAQsnhgAHimKYuYDi0ZiABpDDABfW+/Op1H2e3WPAcyJGAAec+XZP6i8b+Bw+26MBh5JDE0hBoDHXLj2TBStdt1jAEskBoDHrGxcnSkGxuPS9kJoCDEAPGb1wqXJtoLKdf3ew6XMAyyeGAAeM7lfYJY9Bf3d+5PLA0uYCFg0MQCcyuEkBkIMQBOIAeCIorNSuebOv77vKYTQEGIAOOJbL71WuWY88tAhaAoxABzRvXit7hGAJRIDwBHdzdlioBx68BA0gRgATh0Dg90HC58FWDwxABwx6xMID3buLXwWYPHEAHBqvVs/r3sEYA7EAHBq9z75Ud0jAHMgBoCjilZcff7luqcAlkQMAEcURSs2n/qdmdY6rAjOPzEAHFUUsTrTjoJxjGwvhHNPDADHn15YYTwaxcDphXDuiQHgiKIoomh1qheOR44yhgYQA8CplYPD+OKTj+oeAzgjMQCcoDj5j8ejONz9YlnDAAsiBoCvtLJxJa5954d1jwEsgRgAvlKr1YnOevVNhBO2F8L5JgaAr1S0O7Ey046C0vZCOOfEAHDsYUWd7kblukkIDA92lzITsBhiADh+e2FRcQOhGIBGEAPAmZT9/ejbUQDnmhgAjtVZuxid9c0T10yeQLh7+xdLmwmYPzEAHKt7+UasX/123WMACyYGgGO1V9aivbo+01rbC+H8EgPAsSYhMEsMjAaHMS6HS5kJmD8xAByrvdKdXh2oMuz3ohwcLGUmYP7EAHBmw8O96dUB4HwSA8CZ7d37LA6279Y9BnBKYgA4s+H+dpT9vbrHAE5JDAAn+o0XfhDdzet1jwEskBgATjQ5rKjorFauG49GthfCOSUGgBNNnkDYaq9Urhse9iZFsJSZgPkSA0Dl9sLJCYZVhntbMRqVS5kJmK/OnD8f8A00Go2mr9Orvvzf39uKYf8wxmf4P8bklMR2uzo8gPlyZQASeOedd2J9ff3Ur48++lHl17j3H/8Y3//Oc2f6Oq+//vpS/j2Ax7kyAAlMrgoMh6d/XPBnd7bid5+7Hu3WSf9/GE+/xlm+zln+LnB6rgwAlf7mxz+P/uDL+wH2yovxy/3vxSe9l+PTvd+LB4MbdY8HnJErA0ClOw96MRqPY3d4JX62+0fRKy/HcLwarShjvb0Tv7X+s/jNtf+Mdquoe1TgFMQAUOn2g14clt34Se+N6I9/fYrhKDrRK6/Gv+++GqvFYVy/vBH/dWur1lmBr8/bBECl3f1+/MP9P3ssBP6/Mlbin3dei8tXng7XBuD8EQPAnDYXFvHK95+ebg8EzhcxAMzNH7/8fGgBOH/EAAAkJwaAmfz07/88WvHVzwEoooyXLv5drLe3lz4XcHZiAJjJrdufxatX/jIutB9GOwbTuwgmEVCUD+P68P0Ybv04Pv7lvbrHBE7B1kJgJp/f34n14l48M/yL+Le734r/fdCO7d2HMd77JO786l+mTyn8n7vbUY4cYwznTTGe8QDyt99+e/HTAAtx8+bN+OCDD870OTrtVvzJD3877m3tTV9fbO3H/Z39mKennnoq3njjjbl+Tsju3Xffnd+Vgbfeeuus8wA1ee+9984cA8NyFH/1wcexSE8++aTvNVCDmWPglVdeWewkwMJ8+OGHcR5sbm76XgM1cAMhACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5pxZCAi+88EK8+eab8U334osv1j0CpDTzqYUAQDN5mwAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQCI3P4PcGSMR6GERQcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished. Total reward: 10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def render_frame(env):\n",
    "    \"\"\"Render a single frame of the environment using matplotlib.\"\"\"\n",
    "    frame = env.render()    # Get the current frame\n",
    "    plt.imshow(frame)       # Display the frame\n",
    "    plt.axis(\"off\")         # Turn off axis labels\n",
    "    plt.show(block=False)   # Show the frame without blocking\n",
    "    plt.pause(0.001)        # Small pause for smoother animation\n",
    "    plt.clf()               # Clear figure for the next frame\n",
    "\n",
    "\n",
    "def run_cartpole(seed: int = 42, episodes: int = 1):\n",
    "    \"\"\"Run the CartPole environment with a simple policy (always move right).\"\"\"\n",
    "    env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state, info = env.reset(seed=seed if ep == 0 else None)\n",
    "        print(f\"\\nEpisode {ep + 1} — Initial state: {state}\")\n",
    "\n",
    "        terminated, truncated = False, False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not (terminated or truncated):\n",
    "            action = 1  # Simple policy: always move right\n",
    "            state, reward, terminated, truncated, info = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            render_frame(env)\n",
    "\n",
    "        print(f\"Episode {ep + 1} finished. Total reward: {total_reward}\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_cartpole(episodes=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
